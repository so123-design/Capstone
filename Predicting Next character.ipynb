{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Input, Embedding, Reshape, merge, LSTM, Bidirectional\n",
    "from keras.layers import SimpleRNN, TimeDistributed\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Conv1D, MaxPooling1D, ZeroPadding1D\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import Adam\n",
    "import cPickle as pickle\n",
    "import bcolz\n",
    "import re\n",
    "from numpy.random import random, permutation, randn, normal, uniform, choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600901\n"
     ]
    }
   ],
   "source": [
    "path = get_file('nietzsche.txt', origin=\"https://s3.amazonaws.com/text-datasets/nietzsche.txt\")\n",
    "text = open(path).read()\n",
    "print len(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a vocabulary of unique characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "print len(chars)+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inserting 0 as it wasn't in the original text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chars.insert(0, '\\0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a dictionary, mapping characters to index and index to characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "char_to_index = {v:i for i,v in enumerate(chars)}\n",
    "index_to_char = {i:v for i,v in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the entire nietzsche text into index of characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_index = [char_to_index[char] for char in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[40, 42, 29, 30, 25, 27, 29, 1, 1, 1]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_index[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PREFACE\\n\\n\\nSUPPOSING that '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(index_to_char[i] for i in total_index[:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As were are predicting the 8th character, we need to create an array of the first 7 characters each acting as an input and the last character as the output.\n",
    "\n",
    "For example, for the text 'this and that'\n",
    "\n",
    "The input will be -> [['t', ' '], ['h', 't'], ['i', 'h'], ['s', 'a'], [' ', 't'], ['a'], ['n']] -> but instead of the characters, there will be the index of the character.\n",
    "\n",
    "And the output will be -> ['d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_num = 25\n",
    "xin = [[total_index[j+i] for j in xrange(0, len(total_index)-1-pred_num, pred_num)] for i in range(pred_num)]\n",
    "y = [total_index[i+pred_num] for i in xrange(0, len(total_index)-1-pred_num, pred_num)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are removing the last 2 characters to keep the length of each array equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = [np.stack(xin[i][:-2]) for i in range(pred_num)]\n",
    "Y = np.stack(y[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([40, 44, 58, ..., 76, 78, 62]),\n",
       " array([42, 71, 67, ..., 58,  2, 54]),\n",
       " array([29, 74, 24, ..., 71, 73, 65]),\n",
       " array([30, 73,  2, ..., 72, 61,  2]),\n",
       " array([25, 61, 33, ...,  2, 58, 73]),\n",
       " array([27,  2, 72, ..., 76,  1, 68]),\n",
       " array([29, 62,  2, ..., 58, 26,  2]),\n",
       " array([ 1, 72, 73, ..., 71, 74, 72]),\n",
       " array([ 1,  2, 61, ..., 58, 57, 54]),\n",
       " array([ 1, 54, 58, ...,  2, 57, 67]),\n",
       " array([43,  2, 71, ..., 62, 61, 56]),\n",
       " array([45, 76, 58, ..., 67, 62, 73]),\n",
       " array([40, 68,  2, ..., 72, 72, 62]),\n",
       " array([40, 66, 67, ..., 62, 73, 73]),\n",
       " array([39, 54, 68, ..., 72, 72, 78]),\n",
       " array([43, 67, 73, ..., 73,  2,  8]),\n",
       " array([33,  9,  2, ..., 58, 54,  2]),\n",
       " array([38,  9, 60, ..., 57, 72, 63]),\n",
       " array([31, 76, 71, ...,  2,  2, 74]),\n",
       " array([ 2, 61, 68, ..., 74, 58, 72]),\n",
       " array([73, 54, 74, ..., 69, 72, 73]),\n",
       " array([61, 73, 67, ..., 68, 72,  2]),\n",
       " array([54,  2, 57, ..., 67, 58, 54]),\n",
       " array([73, 73,  1, ...,  2, 67, 72]),\n",
       " array([ 2, 61, 59, ..., 55, 73,  2])]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([44, 58, 68, 62, 73,  8, 67, 65])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24033,), (24033,))"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_layers = 256\n",
    "vocab_size = 86\n",
    "n_fac = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "        Embedding(vocab_size, n_fac, input_length=pred_num),\n",
    "        SimpleRNN(hidden_layers, activation='relu'),\n",
    "        Dense(vocab_size, activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 7, 42)             3612      \n",
      "_________________________________________________________________\n",
      "simple_rnn_6 (SimpleRNN)     (None, 256)               76544     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 86)                22102     \n",
      "=================================================================\n",
      "Total params: 102,258.0\n",
      "Trainable params: 102,258\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.fit(np.stack(X, 1), Y, batch_size=64, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('simpleRNN_3pred.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('simpleRNN_3pred.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('simpleRNN_7pred.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.load_weights('simpleRNN_7pred.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First convert the input to indices\n",
    "2. Then expand the dimension to match the model's output format\n",
    "3. Predict the 8th character using the input\n",
    "4. As we are using softmax activation in the last layer of the model, we get the probability of every 86 characters in our vocabulary. So the character with the maximum probability will be the 8th predicted character by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_next_char(inp):\n",
    "    index = [char_to_index[i] for i in inp]\n",
    "    arr = np.expand_dims(np.array(index), axis=0)\n",
    "    prediction = model.predict(arr)\n",
    "    return index_to_char[np.argmax(prediction)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, prediction is being done for the 8th character(pred_num = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'h'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_next_char('those w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, prediction is being done for the 4th character, so just set pred_num = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_next_char(' th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_next_char(' an')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_next_char('does th')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Return Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will predict the next word where the input will be all the words before it.\n",
    "\n",
    "For example, to predict the 2nd word, first word will be used\n",
    "\n",
    "To predict the 3rd word, first and second word will be used and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ys = [[total_index[j+i] for j in xrange(1, len(total_index)-pred_num, pred_num)] for i in range(pred_num)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_return = [np.stack(ys[i][:-2]) for i in range(pred_num)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([40, 44, 58, ..., 76, 78, 62]),\n",
       " array([42, 71, 67, ..., 58,  2, 54]),\n",
       " array([29, 74, 24, ..., 71, 73, 65]),\n",
       " array([30, 73,  2, ..., 72, 61,  2]),\n",
       " array([25, 61, 33, ...,  2, 58, 73]),\n",
       " array([27,  2, 72, ..., 76,  1, 68]),\n",
       " array([29, 62,  2, ..., 58, 26,  2]),\n",
       " array([ 1, 72, 73, ..., 71, 74, 72]),\n",
       " array([ 1,  2, 61, ..., 58, 57, 54]),\n",
       " array([ 1, 54, 58, ...,  2, 57, 67]),\n",
       " array([43,  2, 71, ..., 62, 61, 56]),\n",
       " array([45, 76, 58, ..., 67, 62, 73]),\n",
       " array([40, 68,  2, ..., 72, 72, 62]),\n",
       " array([40, 66, 67, ..., 62, 73, 73]),\n",
       " array([39, 54, 68, ..., 72, 72, 78]),\n",
       " array([43, 67, 73, ..., 73,  2,  8]),\n",
       " array([33,  9,  2, ..., 58, 54,  2]),\n",
       " array([38,  9, 60, ..., 57, 72, 63]),\n",
       " array([31, 76, 71, ...,  2,  2, 74]),\n",
       " array([ 2, 61, 68, ..., 74, 58, 72]),\n",
       " array([73, 54, 74, ..., 69, 72, 73]),\n",
       " array([61, 73, 67, ..., 68, 72,  2]),\n",
       " array([54,  2, 57, ..., 67, 58, 54]),\n",
       " array([73, 73,  1, ...,  2, 67, 72]),\n",
       " array([ 2, 61, 59, ..., 55, 73,  2])]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([42, 71, 67, ..., 58,  2, 54]),\n",
       " array([29, 74, 24, ..., 71, 73, 65]),\n",
       " array([30, 73,  2, ..., 72, 61,  2]),\n",
       " array([25, 61, 33, ...,  2, 58, 73]),\n",
       " array([27,  2, 72, ..., 76,  1, 68]),\n",
       " array([29, 62,  2, ..., 58, 26,  2]),\n",
       " array([ 1, 72, 73, ..., 71, 74, 72]),\n",
       " array([ 1,  2, 61, ..., 58, 57, 54]),\n",
       " array([ 1, 54, 58, ...,  2, 57, 67]),\n",
       " array([43,  2, 71, ..., 62, 61, 56]),\n",
       " array([45, 76, 58, ..., 67, 62, 73]),\n",
       " array([40, 68,  2, ..., 72, 72, 62]),\n",
       " array([40, 66, 67, ..., 62, 73, 73]),\n",
       " array([39, 54, 68, ..., 72, 72, 78]),\n",
       " array([43, 67, 73, ..., 73,  2,  8]),\n",
       " array([33,  9,  2, ..., 58, 54,  2]),\n",
       " array([38,  9, 60, ..., 57, 72, 63]),\n",
       " array([31, 76, 71, ...,  2,  2, 74]),\n",
       " array([ 2, 61, 68, ..., 74, 58, 72]),\n",
       " array([73, 54, 74, ..., 69, 72, 73]),\n",
       " array([61, 73, 67, ..., 68, 72,  2]),\n",
       " array([54,  2, 57, ..., 67, 58, 54]),\n",
       " array([73, 73,  1, ...,  2, 67, 72]),\n",
       " array([ 2, 61, 59, ..., 55, 73,  2]),\n",
       " array([44, 58, 68, ..., 78, 62, 73])]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_size = 86\n",
    "n_fac = 42\n",
    "hidden_layers = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are setting return_sequences=True, we need to wrap the Dense layer in a TimeDistributed Layer since it is a sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "return_model = Sequential([\n",
    "        Embedding(vocab_size, n_fac, input_length=pred_num),\n",
    "        SimpleRNN(hidden_layers, return_sequences=True, activation='relu'),\n",
    "        TimeDistributed(Dense(vocab_size, activation='softmax'))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 25, 42)            3612      \n",
      "_________________________________________________________________\n",
      "simple_rnn_2 (SimpleRNN)     (None, 25, 256)           76544     \n",
      "_________________________________________________________________\n",
      "time_distributed_7 (TimeDist (None, 25, 86)            22102     \n",
      "=================================================================\n",
      "Total params: 102,258.0\n",
      "Trainable params: 102,258\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "return_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "return_model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_model = np.stack(X, 1)\n",
    "Y_model = np.expand_dims(np.stack(Y_return, 1), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "24033/24033 [==============================] - 34s - loss: 2.7874    \n",
      "Epoch 2/5\n",
      "24033/24033 [==============================] - 34s - loss: 2.1312    \n",
      "Epoch 3/5\n",
      "24033/24033 [==============================] - 35s - loss: 1.9243    \n",
      "Epoch 4/5\n",
      "24033/24033 [==============================] - 34s - loss: 1.8067    \n",
      "Epoch 5/5\n",
      "24033/24033 [==============================] - 35s - loss: 1.7328    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa7ac3be0d0>"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_model.fit(X_model, Y_model, batch_size=64, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "24033/24033 [==============================] - 35s - loss: 1.6828    \n",
      "Epoch 2/5\n",
      "24033/24033 [==============================] - 34s - loss: 1.6447    \n",
      "Epoch 3/5\n",
      "24033/24033 [==============================] - 35s - loss: 1.6155    \n",
      "Epoch 4/5\n",
      "24033/24033 [==============================] - 35s - loss: 1.5918    \n",
      "Epoch 5/5\n",
      "24033/24033 [==============================] - 34s - loss: 1.5717    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa7d623e950>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_model.optimizer.lr = 1e-4\n",
    "return_model.fit(X_model, Y_model, batch_size=64, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "24033/24033 [==============================] - 35s - loss: 1.5555    \n",
      "Epoch 2/5\n",
      "24033/24033 [==============================] - 34s - loss: 1.5413    \n",
      "Epoch 3/5\n",
      "24033/24033 [==============================] - 35s - loss: 1.5279    \n",
      "Epoch 4/5\n",
      "24033/24033 [==============================] - 34s - loss: 1.5175    \n",
      "Epoch 5/5\n",
      "24033/24033 [==============================] - 35s - loss: 1.5073    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa7ad2ac810>"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_model.optimizer.lr = 1e-4\n",
    "return_model.fit(X_model, Y_model, batch_size=64, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "return_model.save_weights('return_sequences_25.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_every_char(inp):\n",
    "    l = []\n",
    "    p = 0\n",
    "    while p<len(inp):\n",
    "        pre_inp = inp[p:p+pred_num]\n",
    "        if len(pre_inp) < pred_num:\n",
    "            pre_inp = pre_inp + ' '*(pred_num - len(pre_inp))\n",
    "            l.append(pre_inp)\n",
    "        else:\n",
    "            l.append(pre_inp) \n",
    "        p+=pred_num\n",
    "\n",
    "#     index = [char_to_index[i] for i in inp]\n",
    "#     arr = np.expand_dims(index, axis=0)\n",
    "#     prediction = return_model.predict(arr)\n",
    "#     return ''.join([index_to_char[np.argmax(i)] for i in prediction[0]])\n",
    "    \n",
    "    final = []\n",
    "    for half in l:\n",
    "        index = [char_to_index[i] for i in half]\n",
    "        arr = np.expand_dims(index, axis=0)\n",
    "        prediction = return_model.predict(arr)\n",
    "        final.append(''.join([index_to_char[np.argmax(i)] for i in prediction[0]]))\n",
    "    \n",
    "    return ''.join(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nd the sedsaise t        '"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_every_char('and the boy left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hen as a                 '"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_every_char('this is')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1].oNter tiseng testovere  tn tan  tf the sass aonaletens ole tncuon  aaaelton fest tion  of traasure as tvptionsoor tts swn toye  a helce o hon boperhian the sanf-aonsempt ohenh aoaracterists aawd ar   na  and tslo tt the r tncu of tulf-sh rhre otheeush tamcrr and tehrlseng   aostart nn  and toarn n  tf the safei  ancu af toneess  oomply tnmeans ohire y auch aeture  ouy be tst the srneral txpiusthon of the r pill to tofe aahe r pewver . The  avpeaosohe sost arrn ul axpe  nnc  ao txtepedos tney tor t shme ooom the siaden s  ond thlkingss on thinh ahe  are stip  d ty the r areat tan ul an irenth tnd the r pepject on ooranshll afher ahet the r tfn  T                   '"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_every_char(\"140 After having discovered in many of the less comprehensible actions mere manifestations of pleasure in emotion for its own sake, I fancy I can detect in the self contempt which characterises holy persons, and also in their acts of self torture (through hunger and scourgings, distortions and chaining of the limbs, acts of madness) simply a means whereby such natures may resist the general exhaustion of their will to live (their nerves). They employ the most painful expedients to escape if only for a time from the heaviness and weariness in which they are steeped by their great mental indolence and their subjection to a will other than their own.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stateful Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In stateful model, the model remembers the context i.e. the long-term dependencies. Make sure you set shuffle=False.\n",
    "\n",
    "Because if you set shuffle=True, the order of input will not be preserved, hence the model won't be able to extract the context of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bs = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use ReLU as the activation of LSTM, we get exploding gradients\n",
    "\n",
    "Hence using tanh as the activation keeps the hidden state vector from growing beyond [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stateful_model = Sequential([\n",
    "        Embedding(vocab_size, n_fac, input_length=pred_num, batch_input_shape=(bs, 7)),\n",
    "        BatchNormalization(),\n",
    "        LSTM(hidden_layers, activation='tanh', return_sequences=True, stateful=True),\n",
    "        TimeDistributed(Dense(vocab_size, activation='softmax'))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stateful_model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "divide = len(X_model)//bs*bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "85824/85824 [==============================] - 120s - loss: 2.2224   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa7a72bc750>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stateful_model.fit(X_model[:divide], Y_model[:divide], batch_size=64, epochs=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "85824/85824 [==============================] - 122s - loss: 2.0121   \n",
      "Epoch 2/5\n",
      "85824/85824 [==============================] - 123s - loss: 1.9409   \n",
      "Epoch 3/5\n",
      "85824/85824 [==============================] - 121s - loss: 1.8989   \n",
      "Epoch 4/5\n",
      "85824/85824 [==============================] - 120s - loss: 1.8690   \n",
      "Epoch 5/5\n",
      "85824/85824 [==============================] - 128s - loss: 1.8453   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa7a72a7c90>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stateful_model.fit(X_model[:divide], Y_model[:divide], batch_size=64, epochs=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "85824/85824 [==============================] - 119s - loss: 1.8254   \n",
      "Epoch 2/5\n",
      "85824/85824 [==============================] - 119s - loss: 1.8083   \n",
      "Epoch 3/5\n",
      "85824/85824 [==============================] - 120s - loss: 1.7931   \n",
      "Epoch 4/5\n",
      "85824/85824 [==============================] - 122s - loss: 1.7793   \n",
      "Epoch 5/5\n",
      "85824/85824 [==============================] - 112s - loss: 1.7667   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa7ac020390>"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stateful_model.optimizer.lr = 1e-4\n",
    "stateful_model.fit(X_model[:divide], Y_model[:divide], batch_size=64, epochs=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def predict_every_char_stateful(inp):\n",
    "#     index = [char_to_index[i] for i in inp]\n",
    "#     arr = np.expand_dims(index, axis=0)\n",
    "#     arr = np.resize(arr, (bs, 7))\n",
    "#     prediction = stateful_model.predict(arr, batch_size=64)\n",
    "#     return [index_to_char[np.argmax(i)] for i in prediction[0]]  \n",
    "\n",
    "\n",
    "def predict_every_char_stateful(inp):\n",
    "    l = []\n",
    "    p = 0\n",
    "    while p<len(inp):\n",
    "        pre_inp = inp[p:p+pred_num]\n",
    "        if len(pre_inp) < pred_num:\n",
    "            pre_inp = pre_inp + ' '*(pred_num - len(pre_inp))\n",
    "            l.append(pre_inp)\n",
    "        else:\n",
    "            l.append(pre_inp) \n",
    "        p+=pred_num\n",
    "    \n",
    "    final = []\n",
    "    for half in l:\n",
    "        index = [char_to_index[i] for i in half]\n",
    "        arr = np.expand_dims(index, axis=0)\n",
    "        arr = np.resize(arr, (bs, 7))\n",
    "        prediction = stateful_model.predict(arr, batch_size=64)\n",
    "        final.append(''.join([index_to_char[np.argmax(i)] for i in prediction[0]]))\n",
    "    return ''.join(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ien cn '"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_every_char_stateful('this is')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4\\n\\nsnter teveng tostoueryd tn tan  of the soas aonpaehen iole tntion  aaae iay fest tion  af tleasure os tvotionsoor tt  ofn tuie  t selce onhon besert on the salf aonsemptitiich aaaractedist  tiwd aersona  tnd tllo tn the r snts tf talf ah   ne oaheough temder and tainrsena   tostrrteons and toarn ng tf the sofie  tnt  af taneess  tonply tnsaans oiine y tuch aetura  tay beststethe srneral sxcaueeicn of the r sitl th tofe iahe r secaes   The  axplyy the sost tein ul axperienc  oh txteta on tney tor tnshme aoom the se ryngds ond ti kingds on thich ihe  are seapm d ty the r sreat tan  l sn ilvnce ond the r supject on oh tnsotl tfher ahet the r swn  Tt '"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_every_char_stateful(\"140 After having discovered in many of the less comprehensible actions mere manifestations of pleasure in emotion for its own sake, I fancy I can detect in the self contempt which characterises holy persons, and also in their acts of self torture (through hunger and scourgings, distortions and chaining of the limbs, acts of madness) simply a means whereby such natures may resist the general exhaustion of their will to live (their nerves). They employ the most painful expedients to escape if only for a time from the heaviness and weariness in which they are steeped by their great mental indolence and their subjection to a will other than their own.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
