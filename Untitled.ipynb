{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74c11fbc",
   "metadata": {},
   "source": [
    "# Chatbot Application with Google Gemini-Pro and Streamlit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2da3c3",
   "metadata": {},
   "source": [
    "___________________\n",
    "## Overview\n",
    "This project demonstrates the creation of an interactive chatbot powered by the Google Gemini-Pro model, integrated into a user-friendly web application built with Streamlit. The goal is to build a platform where users can have real-time conversations with the AI model, leveraging its capabilities to provide insightful responses based on user input. The project makes use of environment variables for API configuration, Streamlit for the frontend, and the Google Gemini-Pro API for natural language processing (NLP).\n",
    "\n",
    "This simple yet effective chatbot can be used in various applications such as customer service, virtual assistants, or any other domain where a conversational AI can add value. The project focuses on setting up a conversation flow, maintaining chat history, and handling user inputs and AI responses dynamically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d48984",
   "metadata": {},
   "source": [
    "_________________\n",
    "## Project Steps\n",
    "- **Setting Up the Environment**\n",
    "The project begins by importing necessary libraries such as Streamlit for the web interface, dotenv for loading environment variables, and google.generativeai for connecting to the Gemini-Pro model. The Google API key is loaded securely from environment variables to maintain privacy.\n",
    "\n",
    "- **Streamlit Page Configuration**\n",
    "The Streamlit page is configured with a title, an icon (emoji), and a layout that centers the content. This ensures a clean and engaging user interface for the chatbot.\n",
    "\n",
    "- **Google Gemini-Pro API Configuration**\n",
    "The API key is retrieved from the environment, and the google.generativeai library is configured to interact with the Gemini-Pro model. This model is then initialized to handle user inputs and generate responses accordingly.\n",
    "\n",
    "- **Role Translation for Streamlit**\n",
    "A helper function is created to translate the roles between the Gemini-Pro modelâ€™s terminology (like model and user) and the role expected by Streamlit for displaying messages (like assistant and user). This ensures the chat message display is formatted correctly.\n",
    "\n",
    "- **Initializing Chat Session**\n",
    "If a chat session doesn't already exist in the Streamlit session state, a new session is started using model.start_chat(). This allows the chatbot to remember the context and flow of the conversation, making the interaction feel continuous for the user.\n",
    "\n",
    "- **Displaying Chat History**\n",
    "The chat history, including messages from both the user and the assistant, is displayed using Streamlit's st.chat_message() feature. This shows previous conversation exchanges, ensuring that the user sees the full context of their chat.\n",
    "\n",
    "- **User Input and AI Response**\n",
    "A chat input field is provided for the user to enter their query. When the user submits a message, it is sent to Gemini-Pro via the API, and the response is displayed in the chat window. This back-and-forth exchange forms the core functionality of the chatbot.\n",
    "\n",
    "- **Streamlit Chat Features**\n",
    "Streamlitâ€™s interactive components like st.chat_message and st.chat_input are utilized to create a real-time, seamless conversation flow. The chatbot responds instantly, making it easy for users to engage in a dialogue with Gemini-Pro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e362ac4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import streamlit as st\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as gen_ai\n",
    "\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Configure Streamlit page settings\n",
    "st.set_page_config(\n",
    "    page_title=\"Chat with Gemini-Pro!\",\n",
    "    page_icon=\":brain:\",  # Favicon emoji\n",
    "    layout=\"centered\",  # Page layout option\n",
    ")\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "# Set up Google Gemini-Pro AI model\n",
    "gen_ai.configure(api_key=GOOGLE_API_KEY)\n",
    "model = gen_ai.GenerativeModel('gemini-pro')\n",
    "\n",
    "\n",
    "# Function to translate roles between Gemini-Pro and Streamlit terminology\n",
    "def translate_role_for_streamlit(user_role):\n",
    "    if user_role == \"model\":\n",
    "        return \"assistant\"\n",
    "    else:\n",
    "        return user_role\n",
    "\n",
    "\n",
    "# Initialize chat session in Streamlit if not already present\n",
    "if \"chat_session\" not in st.session_state:\n",
    "    st.session_state.chat_session = model.start_chat(history=[])\n",
    "\n",
    "\n",
    "# Display the chatbot's title on the page\n",
    "st.title(\"ðŸ¤– Gemini Pro - ChatBot\")\n",
    "\n",
    "# Display the chat history\n",
    "for message in st.session_state.chat_session.history:\n",
    "    with st.chat_message(translate_role_for_streamlit(message.role)):\n",
    "        st.markdown(message.parts[0].text)\n",
    "\n",
    "# Input field for user's message\n",
    "user_prompt = st.chat_input(\"Ask Gemini-Pro...\")\n",
    "if user_prompt:\n",
    "    # Add user's message to chat and display it\n",
    "    st.chat_message(\"user\").markdown(user_prompt)\n",
    "\n",
    "    # Send user's message to Gemini-Pro and get the response\n",
    "    gemini_response = st.session_state.chat_session.send_message(user_prompt)\n",
    "\n",
    "    # Display Gemini-Pro's response\n",
    "    with st.chat_message(\"assistant\"):\n",
    "        st.markdown(gemini_response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04665149",
   "metadata": {},
   "source": [
    "____________________\n",
    "## Conclusion\n",
    "The chatbot built in this project offers a simple and effective way to interact with Googleâ€™s Gemini-Pro AI model in a conversational interface. By leveraging Streamlit for the frontend and using Googleâ€™s generative AI model, this application allows users to ask questions and receive AI-generated responses in real time. The integration of chat history ensures that the conversation remains contextual, enhancing user experience.\n",
    "\n",
    "Key highlights of the project:\n",
    "\n",
    "- **Seamless Integration:** The smooth integration between Streamlit and the Gemini-Pro model allows for an intuitive user interface.\n",
    "- **Real-Time Interaction:** The chatbot responds in real time, making it suitable for various conversational applications.\n",
    "- **Secure API Usage:** The use of environment variables ensures the Google API key is kept secure.\n",
    "In future iterations, the chatbot could be expanded with additional features such as custom responses, multi-turn conversations, or even voice interaction. This project serves as an excellent demonstration of creating an AI-powered web application that is simple, functional, and scalable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f620d3d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
